# symbol-ground
Does visual fine-tuning ground a language model's symbols?

What does it mean to ground symbols in neural/representational terms?

What are the representational limits of learning purely from language?

Does visual (or other perceptual modalities) experience provide a unique contribution to a language model's representational repetoire?

# symbol-ground
Are there representational limits in learning purely from language?

Does visual fine-tuning ground a language model's symbols?

What does it mean to ground symbols in neural/representational terms?

Does visual (or other perceptual modalities) experience provide a unique contribution to a language model's representational repetoire?